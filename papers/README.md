# Downloaded Papers

1. [ReviewerGPT: An Exploratory Study on Using Large Language Models for Paper Reviewing](2306.00622_ReviewerGPT.pdf)
   - **Authors**: Liu and Shah (2023)
   - **Relevance**: Explores GPT-4 for reviewing, error detection, and verification.
   - **Key Result**: GPT-4 good at errors, bad at "better paper" choice.

2. [The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery](2408.06292_AI_Scientist.pdf)
   - **Authors**: Lu et al. (2024)
   - **Relevance**: Framework for automated science, including automated reviewing (Section 4).
   - **Key Result**: Can generate full papers and reviews.

3. [The AI Scientist-v2: Workshop-Level Automated Scientific Discovery via Agentic Tree Search](2504.08066_AI_Scientist_v2.pdf)
   - **Authors**: Yamada et al. (2025)
   - **Relevance**: Improves v1 with VLM feedback for reviewing figures/tables.
   - **Key Result**: AI-generated paper accepted at ICLR workshop.

4. [MMReview: A Multidisciplinary and Multimodal Benchmark for LLM-Based Peer Review Automation](2508.14146_MMReview.pdf)
   - **Authors**: Gao et al. (2025)
   - **Relevance**: Comprehensive benchmark for LLM reviewing (text + images).
   - **Key Result**: Introduces MMReview benchmark (240 papers, multimodal).

5. [Improving Factuality and Reasoning in Language Models through Multiagent Debate](2305.14325_Multiagent_Debate.pdf)
   - **Authors**: Du et al. (2023)
   - **Relevance**: Core methodology for "Equilibrium" - using multiple agents to improve truthfulness.
   - **Key Result**: Debate improves factuality and math reasoning.
